{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d11a44",
   "metadata": {},
   "source": [
    "# Amazon book review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79b41d",
   "metadata": {},
   "source": [
    "### 1) Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe9096b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re \n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339ed37",
   "metadata": {},
   "source": [
    "### 2) Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a09f518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book first bookmobile book bought school book ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normally buy mystery novels like however time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kind book normally read although try limit cer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bought book loved cover try read civil war rom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book thoroughly enjoyed beginning end story li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Score\n",
       "0  book first bookmobile book bought school book ...      1\n",
       "1  normally buy mystery novels like however time ...      1\n",
       "2  kind book normally read although try limit cer...      1\n",
       "3  bought book loved cover try read civil war rom...      0\n",
       "4  book thoroughly enjoyed beginning end story li...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset from csv file\n",
    "df = pd.read_csv(r'Data/Amazon_reviews_processed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be599b45",
   "metadata": {},
   "source": [
    "### 3) Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16dd80b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "11127    0\n",
       "11128    0\n",
       "11129    1\n",
       "11130    1\n",
       "11131    1\n",
       "Name: Score, Length: 11132, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine data and target\n",
    "X = df['reviewText']\n",
    "y = df['Score']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49c26668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training, validation and Test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a0ed4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (8905,)\n",
      "Shape of X_test: (2227,)\n",
      "Shape of train_vectors: (8905, 2000)\n",
      "Shape of test_vectors: (2227, 2000)\n"
     ]
    }
   ],
   "source": [
    "# I will use TF-IDF method to extract the text features.\n",
    "\n",
    "# Use TF-IDF\n",
    "\n",
    "tf_vec = TfidfVectorizer(tokenizer=None, stop_words=None, max_df=0.75, max_features=2000, lowercase=False,\n",
    "                         ngram_range=(1,2), use_idf=False, sublinear_tf=True, min_df=5, norm='l2',\n",
    "                         encoding='latin-1')\n",
    "\n",
    "\n",
    "train_features = tf_vec.fit(X_train)\n",
    "train_features = tf_vec.transform(X_train)\n",
    "test_features = tf_vec.transform(X_test)\n",
    "\n",
    "\n",
    "print('Shape of X_train:',X_train.shape)\n",
    "print('Shape of X_test:',X_test.shape)\n",
    "print('Shape of train_vectors:',train_features.shape)\n",
    "print('Shape of test_vectors:',test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2c40c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programfiles\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Vectorization of data\n",
    "## Vectorize the data using Bag of words (BOW)\n",
    "\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r\"\\w+\")\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "tf_vec = CountVectorizer(tokenizer=tokenizer.tokenize, stop_words=stop_words)\n",
    "\n",
    "train_features = tf_vec.fit(X_train)\n",
    "train_features = tf_vec.transform(X_train)\n",
    "test_features = tf_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce417fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save tfidf vectorizer\n",
    "with open('Vectors/train_vector.pkl', 'wb') as handle:\n",
    "    pickle.dump(train_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('Vectors/test_vector.pkl', 'wb') as handle:\n",
    "    pickle.dump(test_features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cdc7558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save Target Varab\n",
    "\n",
    "with open('Vectors/train_label.pkl', 'wb') as handle:\n",
    "    pickle.dump(y_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('Vectors/test_label.pkl', 'wb') as handle:\n",
    "    pickle.dump(y_test, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889bb34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
